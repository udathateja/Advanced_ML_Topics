{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-0pHMM27VrK"
      },
      "source": [
        "## Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf7n79bk7VrP"
      },
      "source": [
        "Gradient descent is an optimization algorithm used to find the values of parameters (coefficients) of a function (f) that minimizes a cost function (cost).\n",
        "\n",
        "The gradient descent method is an iterative optimization algorithm that operates over a loss landscape.We can visualize our loss landscape as a bowl, similar to the one you may eat cereal or soup out of:The surface of our bowl is called our loss landscape, which is essentially a plot of our loss function.\n",
        "\n",
        "The difference between our loss landscape and your cereal bowl is that your cereal bowl only exists in three dimensions, while your loss landscape exists in many dimensions, perhaps tens, hundreds, or even thousands of dimensions.\n",
        "Each position along the surface of the bowl corresponds to a particular loss value given our set of parameters, W (weight matrix) and b (bias vector).\n",
        "Our goal is to try different values of W and b, evaluate their loss, and then take a step towards more optimal values that will (ideally) have lower loss.\n",
        "Iteratively repeating this process will allow us to navigate our loss landscape, following the gradient of the loss function (the bowl), and find a set of parameters that have minimum loss and high accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMiEYjHc7VrU"
      },
      "source": [
        "### Cost Function & Gradients\n",
        "\n",
        "The equation for calculating cost function and gradients are as shown below. Please note the cost function is for Linear regression. For other algorithms the cost function will be different and the gradients would have  to be derived from the cost functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH49u0Bu7VrW"
      },
      "source": [
        "<b>Cost Function</b>\n",
        "\n",
        "\\begin{equation}\n",
        "Linear Equation ==> y = mx + c\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "J(x) = 1/n \\sum_{i=1}^{n} (y^{(i)} - y^{(i)}predicted)^2 \n",
        "\\end{equation}\n",
        "\n",
        "<b>Gradient</b>\n",
        "\n",
        "**Derivative of cost function with respect to   m   ==>  slope**\n",
        "\\begin{equation}\n",
        "\\frac{\\partial J(x^{(i)})}{\\partial m} = -2/n\\sum_{i=1}^{n}(x^{(i)}).(y^{(i)} - (mx^{(i)} + b))\n",
        "\\end{equation}\n",
        "\n",
        "**Derivative of cost function with respect to   c   ==>  intercept**\n",
        "\\begin{equation}\n",
        "\\frac{\\partial J(x^{(i)})}{\\partial c} = -2/n\\sum_{i=1}^{n}(y^{(i)} - (mx^{(i)} + b))\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ylKJNRS7VrY"
      },
      "source": [
        "Why do we take derivative?\n",
        "\n",
        "To get the direction of where is minimum. If we are on left side of minimum value of parabola then the derivate is negative and negative sign before derivate will make the new value of X go right and thus more closer to minimum value. Vice versa for right side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNvfb5bB7Vra"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0dfGFtP7Vrb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x_a = np.array([1,2,3,4,6,8,3,9,4,5,6,8,9,11,15,7,8,9,13,15,17,19,21])\n",
        "y_a = np.array([9,7,8,10,12,14,12,15,16,13,17,15,15,17,19,23,27,23,25,28,27,24,29])\n",
        "iteration = 1500\n",
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mfi3uuyh7Vrc"
      },
      "outputs": [],
      "source": [
        "## lets take a simple linear regression example to fit the best line decreasing the error.\n",
        "## Gradient is the derivative of loss function. Loss function is the SSE.\n",
        "## We take derivative of SSE and use this Gradient to find the global minima where the loss is almost equal to zero.\n",
        "## at this point our model will get best fitted line.\n",
        "\n",
        "def gradient_descent_linear_line(x,y,iteration,learning_rate):\n",
        "    ## Linear line equation y = mx + c\n",
        "    ## so 1st we need to choose random value of m and c\n",
        "    m_current = 0   \n",
        "    c_current = 0\n",
        "    iteration = iteration  ## select the number of iteration to reach global minima\n",
        "    learning_rate = learning_rate\n",
        "    n = len(x_a) ##  number of samples\n",
        "    for i in range(iteration):\n",
        "        y_a_pred = c_current + m_current * x  ## get intial predecited value\n",
        "        ## now calculate the cost function  J(x) = 1/n(actual_target - prected_target)**2\n",
        "        ## Now transform this equtaion in python\n",
        "        cost_function = 1/n * sum([val**2 for val in (y-y_a_pred)])  ## sum of squared mean error == loss function\n",
        "        # now we have to find the partial derivative of this cost fucntion which will be actullay a Gradient\n",
        "        m_gradient = -2/n * sum(x_a*(y_a - y_a_pred)) ### derivative of MSE with respect to m\n",
        "        c_gradient = -2/n * sum(y_a - y_a_pred) ### derivative of MSE with respect to c\n",
        "        ### Now calculate the step size for intercept(c) and slope(m)\n",
        "        ## c(new) = c(old) - d_c\n",
        "        ## m(new) = m(old) - d_m\n",
        "        m_current = m_current - m_gradient * learning_rate\n",
        "        c_current = c_current - m_gradient * learning_rate\n",
        "        print(\"Iterations {},m {},c {},cost_value {}\".format(i,m_current,c_current,cost_function))\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40TAvSU_7Vre"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x_a,y_a,color = \"blue\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9SvBx3I7Vrg"
      },
      "outputs": [],
      "source": [
        "gradient_descent_linear_line(x_a,y_a,iteration,learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDEOl0gU7Vri"
      },
      "source": [
        "Change the iteration values a observer the change in cost_value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nnJBXJ57Vri"
      },
      "outputs": [],
      "source": [
        "## Now plot grapg to show the regression best fit line \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def gradient_descent_best_fit_line(x_a,y_a,iteration,learning_rate):\n",
        "    m_current = 0\n",
        "    c_current = 0\n",
        "    iter = iteration\n",
        "    n = len(x_a)\n",
        "    learning_rate = learning_rate\n",
        "    plt.scatter(x_a,y_a,color = \"red\")\n",
        "    for i in range(iter):\n",
        "        ## y = mx + c\n",
        "        y_a_pred = m_current * x_a + c_current\n",
        "        ## SSE equation == cost_function\n",
        "        cost_value = 1/n*sum([val**2 for val in (y_a - y_a_pred)])\n",
        "        ## lets take derivative\n",
        "        m_gradient = -2/n * sum(x_a*(y_a - y_a_pred))\n",
        "        c_gradient = -2/n * sum(y_a - y_a_pred)\n",
        "        plt.plot(x_a,y_a_pred,color = \"blue\",linewidth='.1') \n",
        "        m_current = m_current - learning_rate * m_gradient\n",
        "        c_current = c_current - learning_rate * c_gradient\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de4QpEox7Vrk"
      },
      "outputs": [],
      "source": [
        "gradient_descent_best_fit_line(x_a,y_a,iteration,learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xv4jV1Jb7Vrl"
      },
      "outputs": [],
      "source": [
        "## Plot the cost with each iteration\n",
        "import matplotlib.pyplot as plt\n",
        "def sse_cost_plot(x_a,y_a,iteration,learning_rate):\n",
        "    m_current = 0\n",
        "    c_current = 0\n",
        "    iter = iteration\n",
        "    n = len(x_a)\n",
        "    learning_rate = learning_rate\n",
        "    cost_list = [] # list to store the cost in each iteration\n",
        "    intercept = []\n",
        "    coefficient = []\n",
        "    n = len(x_a)\n",
        "    for i in range(iteration):\n",
        "        y_a_pred = (m_current * x_a) + c_current\n",
        "        cost = 1/n * sum([data**2 for data in (y_a - y_a_pred)])\n",
        "        cost_list.append(cost) ## append the cost \n",
        "        m_gradient = -(2/n) * sum(x_a * (y_a - y_a_pred))\n",
        "        c_gradient = -(2/n) * sum(y_a - y_a_pred)\n",
        "        m_current = m_current - (learning_rate * m_gradient)\n",
        "        coefficient.append(m_current)\n",
        "        c_current = c_current - (learning_rate * c_gradient)\n",
        "        intercept.append(c_current)\n",
        "    return intercept,coefficient,cost_list\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jv-CgUXq7Vrm"
      },
      "outputs": [],
      "source": [
        "\n",
        "intercept,coefficient,cost_list = sse_cost_plot(x_a, y_a, iteration,learning_rate)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SazSF0An7Vrm"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(list(range(iteration)), cost_list, '.r')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rm725qT7Vrn"
      },
      "source": [
        "## Optimise Linear Regression using Gradient descent(minimize the cost function) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUS4FIgX7Vro"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIlrJ8187Vrp"
      },
      "outputs": [],
      "source": [
        "df_house = pd.read_csv(\"https://raw.githubusercontent.com/atulpatelDS/Data_Files/master/Houce_Price/train.csv\")\n",
        "df_house.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KC6ZUYr57Vrq"
      },
      "outputs": [],
      "source": [
        "df_house.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3j0WDO-x7Vrq"
      },
      "outputs": [],
      "source": [
        "df_house.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HVGAaT47Vrr"
      },
      "outputs": [],
      "source": [
        "print(df_house.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ptl4nLr7Vrr"
      },
      "outputs": [],
      "source": [
        "X = df_house[[\"GrLivArea\",\"OverallQual\",\"MSSubClass\"]]\n",
        "Y = df_house[\"SalePrice\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aRl7rS37Vrs"
      },
      "outputs": [],
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(type(X))\n",
        "print(type(Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFpcn_kx7Vru"
      },
      "outputs": [],
      "source": [
        "#Y = Y.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oveIwIBh7Vrv"
      },
      "outputs": [],
      "source": [
        "X = (X - X.mean()) / X.std()\n",
        "Y = (Y - Y.mean()) / Y.std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I486Wg367Vrv"
      },
      "outputs": [],
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(type(X))\n",
        "print(type(Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boAOx6xz7Vrw"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state=42)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)\n",
        "print(type(X_train))\n",
        "print(type(Y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mom3VaiQ7Vrx"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn import metrics\n",
        "\n",
        "lin_model = LinearRegression()\n",
        "lin_model.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "QCAt0xMt7Vry"
      },
      "outputs": [],
      "source": [
        "# model evaluation for training set\n",
        "y_train_predict = lin_model.predict(X_train)\n",
        "rmse_train = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))\n",
        "r2_train = metrics.r2_score(Y_train, y_train_predict)\n",
        "\n",
        "print(\"The model performance for training set\")\n",
        "print(\"--------------------------------------\")\n",
        "print('RMSE is {}'.format(rmse_train))\n",
        "print('R2 score is {}'.format(r2_train))\n",
        "print(\"\\n\")\n",
        "\n",
        "# model evaluation for testing set\n",
        "y_test_predict = lin_model.predict(X_test)\n",
        "rmse_test = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))\n",
        "r2_test = metrics.r2_score(Y_test, y_test_predict)\n",
        "\n",
        "print(\"The model performance for testing set\")\n",
        "print(\"--------------------------------------\")\n",
        "print('RMSE is {}'.format(rmse_test))\n",
        "print('R2 score is {}'.format(r2_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YefNSQ527Vry"
      },
      "outputs": [],
      "source": [
        "lin_model.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1kkj-j_7Vrz"
      },
      "outputs": [],
      "source": [
        "lin_model.intercept_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "YXy7AUEW7Vr0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize= (14,4))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.scatter(X_train[\"GrLivArea\"], Y_train)\n",
        "plt.xlabel('GrLivArea')\n",
        "plt.ylabel('SalePrice')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.scatter(X_train[\"OverallQual\"], Y_train)\n",
        "plt.xlabel('OverallQual')\n",
        "plt.ylabel('SalePrice')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.scatter(X_train[\"MSSubClass\"], Y_train)\n",
        "plt.xlabel('MSSubClass')\n",
        "plt.ylabel('SalePrice')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbAat1vb7Vr2"
      },
      "source": [
        "Linear regression via gradient descent is conceptually a simple algorithm. Although, for advanced learning algorithms, the basic concepts remain same but the linear model is replaced by a much more complex model and, correspondingly, a much more complex cost function.\n",
        "\n",
        "We are using boston dataset so there are many columns in datasets if we use all then we can build linear equation  — as shown below.\n",
        "\n",
        "Selling Price of house  = Theta1 * [Feature1] + Theta2 * [Feature2] + Theta3 *             [Feature3] + …… + ThetaM * [FeatureM]\n",
        "\n",
        "Feature values are numerical values. Theta are the coefficients. If we can tune the value of theta according to the data we have, we can just plug in the value for features for new data and we get the sale price for house. So our job is to tune these parameters now.\n",
        "\n",
        "We can convert Linear Regression equation to error function. And then use gradient descent(algorithm to find the minimum of the function) to minimize this error function. As we minimize the error function, our coefficient of linear regression(theta) will get tuned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT6gBCVx7Vr4"
      },
      "source": [
        "Now we will have to convert Linear Regression to error function.Lets our data has total rows = N\n",
        "\n",
        "First we will take value of theta is zero for 1st iteration.\n",
        "For each row in the data, get the estimated selling price.\n",
        "\n",
        "Selling Price = Theta1 * [Feature1] + Theta2 * [Feature2] + Theta3 *             [Feature3] + …… + ThetaM * [FeatureM]\n",
        "\n",
        "Now subtract this from actual selling price. This is our error for one row in data. Square this error. (So that it can we modified in Gradient)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Qvd1Vvz7Vr4"
      },
      "source": [
        "Now do this for all N rows and add this squared error. Divide by N to get mean squared error for current value of theta.\n",
        "This is our error function. If we can minimize this value by gradient descent, then we will be able to minimized our error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ranJEY8m7Vr5"
      },
      "source": [
        "#####  We can wrire error like below\n",
        "Error(θ) = (Σ ((Data * θ — Selling_Price) ^ 2) ) / N\n",
        "\n",
        "Where Data is matrix of size N * M which contains the M feature values of N rows of data., θ is a matrix of size M * 1 , And Selling_Price is the matrix of size N * 1which contains actual selling price of house."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMxIb_2Y7Vr6"
      },
      "source": [
        "In gradient descent, we do Error(θ) = Error(θ) — ( Learning Rate) * Error`(θ)\n",
        "\n",
        "where Error`(θ) is the derivative of Error(θ)\n",
        "\n",
        "To get the new value, we need derivative of Error(θ). Also known as gradient.\n",
        "\n",
        "Data` * (Data * (θ) - Y)\n",
        "\n",
        "Where Data` Represents transpose of Data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVmpW5Nq7Vr6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwY0dnPI7Vr7"
      },
      "outputs": [],
      "source": [
        "# scale the predictor variable, and add a column of 1s for the gradient descent...\n",
        "x = X_train\n",
        "y = Y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLOdVYaT7Vr8"
      },
      "outputs": [],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw_kr_7A7Vr8"
      },
      "outputs": [],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVNNSCGD7Vr9"
      },
      "outputs": [],
      "source": [
        "x = np.c_[np.ones(X_train.shape[0]), X_train] ### we add this column for intercept and take initial value 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl8KbWB37Vr9"
      },
      "outputs": [],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csFgHkeV7Vr-"
      },
      "outputs": [],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pboBoU77Vr-"
      },
      "outputs": [],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUEFR9pc7Vr-"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tV6xkkS37Vr_"
      },
      "outputs": [],
      "source": [
        "alpha = 0.01 #Step size\n",
        "iterations = 1600 #No. of iterations\n",
        "m = y.size #No. of data points\n",
        "np.random.seed(123) #Set the seed\n",
        "theta = np.random.rand(4) #Pick some random values to start with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaUj8deC7VsA"
      },
      "outputs": [],
      "source": [
        "#GRADIENT DESCENT\n",
        "def gradient_descent(x, y, theta, iterations, alpha):\n",
        "    costs = []\n",
        "    thetas = []\n",
        "    for i in range(iterations):\n",
        "        y_pred = np.dot(x, theta)\n",
        "        error = y_pred - y\n",
        "        cost = round((1/(2*m) * np.dot(error.T, error)),4)\n",
        "        costs.append(cost)\n",
        "        theta = theta - (alpha * (1/m) * np.dot(x.T, error))\n",
        "        thetas.append(theta)\n",
        "        print(\"Iteration : {}, theta: {},cost_value {}\".format(i, theta,cost))\n",
        "        \n",
        "        #print(\"Iteration : {}, intercept: {:.2f},coeff1: {:.2f},coeff2 : {:.2f},cost_value {}\".format(i, theta[0],theta[1],theta[2],cost))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uy5R3L1d7VsA"
      },
      "outputs": [],
      "source": [
        "gradient_descent(x, y, theta, iterations, alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKCyi1y-7VsB"
      },
      "outputs": [],
      "source": [
        "#GRADIENT DESCENT\n",
        "def gradient_descent_cost(x, y, theta, iterations, alpha):\n",
        "    costs = []\n",
        "    thetas = []\n",
        "    for i in range(iterations):\n",
        "        y_pred = np.dot(x, theta)\n",
        "        error = y_pred - y\n",
        "        cost = 1/(2*m) * np.dot(error.T, error)\n",
        "        costs.append(cost)\n",
        "        theta = theta - (alpha * (1/m) * np.dot(x.T, error))\n",
        "        thetas.append(theta)        \n",
        "    return thetas, costs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pd6NoseE7VsC"
      },
      "outputs": [],
      "source": [
        "thetas, costs = gradient_descent_cost(x, y, theta, iterations, alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWzItSFS7VsC"
      },
      "outputs": [],
      "source": [
        "#Plot the cost function...\n",
        "#plt.plot(costs)\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.title('Cost Function J')\n",
        "plt.xlabel('No. of iterations')\n",
        "plt.ylabel('Cost')\n",
        "plt.plot(list(range(iterations)), costs, '.r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVHdzZ_j7VsD"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "sgd = SGDRegressor(max_iter=2500,alpha=0.01)\n",
        "sgd.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaj3DQw57VsD"
      },
      "outputs": [],
      "source": [
        "# model evaluation for training set\n",
        "y_train_predict_sgd = sgd.predict(X_train)\n",
        "rmse_train_sgd = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))\n",
        "r2_train_sgd = metrics.r2_score(Y_train, y_train_predict)\n",
        "\n",
        "print(\"The model performance for training set\")\n",
        "print(\"--------------------------------------\")\n",
        "print('RMSE is {}'.format(rmse_train_sgd))\n",
        "print('R2 score is {}'.format(r2_train_sgd))\n",
        "print(\"\\n\")\n",
        "\n",
        "# model evaluation for testing set\n",
        "y_test_predict_sgd = lin_model.predict(X_test)\n",
        "rmse_test_sgd = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))\n",
        "r2_test_sgd = metrics.r2_score(Y_test, y_test_predict)\n",
        "\n",
        "print(\"The model performance for testing set\")\n",
        "print(\"--------------------------------------\")\n",
        "print('RMSE is {}'.format(rmse_test_sgd))\n",
        "print('R2 score is {}'.format(r2_test_sgd))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SELkT4XX7VsE"
      },
      "outputs": [],
      "source": [
        "print(\"Value of Sklearn SGD => intercept: {},coeff: {},cost_value: {}\\n\".format(sgd.intercept_,sgd.coef_,rmse_test_sgd))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvPBc0T17VsF"
      },
      "outputs": [],
      "source": [
        "print(\"Value for Sklearn LG=> intercept: {},coeff: {},cost_value: {}\\n\".format(lin_model.intercept_,lin_model.coef_,rmse_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3eum-zp7VsF"
      },
      "outputs": [],
      "source": [
        "print(\"Value with GD => intercept:coeff1:coeff2 :{},cost_value : {}\\n\".format(thetas[-1],costs[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zIkz8tq7VsH"
      },
      "outputs": [],
      "source": [
        "#Animation\n",
        "\n",
        "#Set the plot up,\n",
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "plt.title('Sale Price vs Living Area')\n",
        "plt.xlabel('Living Area in square feet (normalised)')\n",
        "plt.ylabel('Sale Price ($)')\n",
        "plt.scatter(x[:,1], y, color='red')\n",
        "line, = ax.plot([], [], lw=2)\n",
        "annotation = ax.text(-1, 700000, '')\n",
        "annotation.set_animated(True)\n",
        "plt.close()\n",
        "\n",
        "#Generate the animation data,\n",
        "def init():\n",
        "    line.set_data([], [])\n",
        "    annotation.set_text('')\n",
        "    return line, annotation\n",
        "\n",
        "# animation function.  This is called sequentially\n",
        "def animate(i):\n",
        "    x = np.linspace(-5, 20, 1000)\n",
        "    y = thetas[i][1]*x + thetas[i][0]\n",
        "    line.set_data(x, y)\n",
        "    annotation.set_text('Cost = %.2f e10' % (costs[i]/10000000000))\n",
        "    return line, annotation\n",
        "\n",
        "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
        "                               frames=300, interval=0, blit=True)\n",
        "\n",
        "anim.save('animation.gif', writer='imagemagick', fps = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zF7CtDXo7VsI"
      },
      "outputs": [],
      "source": [
        "#Display the animation...\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "filename = 'animation.gif'\n",
        "\n",
        "video = io.open(filename, 'b+r').read()\n",
        "encoded = base64.b64encode(video)\n",
        "HTML(data='''<img src=\"data:image/gif;base64,{0}\" type=\"gif\" />'''.format(encoded.decode('ascii')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1Z6ozAF7VsI"
      },
      "outputs": [],
      "source": [
        "#Animation\n",
        "\n",
        "#Set the plot up,\n",
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "plt.title('Sale Price vs Living Area')\n",
        "plt.xlabel('Rates the overall material and finish of the house')\n",
        "plt.ylabel('Sale Price ($)')\n",
        "plt.scatter(x[:,2], y, color='red')\n",
        "line, = ax.plot([], [], lw=2)\n",
        "annotation = ax.text(-1, 700000, '')\n",
        "annotation.set_animated(True)\n",
        "plt.close()\n",
        "\n",
        "#Generate the animation data,\n",
        "def init():\n",
        "    line.set_data([], [])\n",
        "    annotation.set_text('')\n",
        "    return line, annotation\n",
        "\n",
        "# animation function.  This is called sequentially\n",
        "def animate(i):\n",
        "    x = np.linspace(-5, 20, 1000)\n",
        "    y = thetas[i][2]*x + thetas[i][0]\n",
        "    line.set_data(x, y)\n",
        "    annotation.set_text('Cost = %.2f e10' % (costs[i]/10000000000))\n",
        "    return line, annotation\n",
        "\n",
        "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
        "                               frames=300, interval=0, blit=True)\n",
        "\n",
        "anim.save('animation1.gif', writer='imagemagick', fps = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqqDs3cG7VsJ"
      },
      "outputs": [],
      "source": [
        "#Display the animation...\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "filename = 'animation1.gif'\n",
        "\n",
        "video = io.open(filename, 'b+r').read()\n",
        "encoded = base64.b64encode(video)\n",
        "HTML(data='''<img src=\"data:image/gif;base64,{0}\" type=\"gif\" />'''.format(encoded.decode('ascii')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6OX1Beg7VsK"
      },
      "outputs": [],
      "source": [
        "#Animation\n",
        "\n",
        "#Set the plot up,\n",
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "plt.title('Sale Price vs Living Area')\n",
        "plt.xlabel('Identifies the type of dwelling involved in the sale')\n",
        "plt.ylabel('Sale Price ($)')\n",
        "plt.scatter(x[:,3], y, color='red')\n",
        "line, = ax.plot([], [], lw=2)\n",
        "annotation = ax.text(-1, 700000, '')\n",
        "annotation.set_animated(True)\n",
        "plt.close()\n",
        "\n",
        "#Generate the animation data,\n",
        "def init():\n",
        "    line.set_data([], [])\n",
        "    annotation.set_text('')\n",
        "    return line, annotation\n",
        "\n",
        "# animation function.  This is called sequentially\n",
        "def animate(i):\n",
        "    x = np.linspace(-5, 20, 1000)\n",
        "    y = thetas[i][3]*x + thetas[i][0]\n",
        "    line.set_data(x, y)\n",
        "    annotation.set_text('Cost = %.2f e10' % (costs[i]/10000000000))\n",
        "    return line, annotation\n",
        "\n",
        "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
        "                               frames=300, interval=0, blit=True)\n",
        "\n",
        "anim.save('animation2.gif', writer='imagemagick', fps = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ymtYnqF7VsK"
      },
      "outputs": [],
      "source": [
        "#Display the animation...\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "filename = 'animation2.gif'\n",
        "\n",
        "video = io.open(filename, 'b+r').read()\n",
        "encoded = base64.b64encode(video)\n",
        "HTML(data='''<img src=\"data:image/gif;base64,{0}\" type=\"gif\" />'''.format(encoded.decode('ascii')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4H4i7UH7VsL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NBRSV_07VsL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import animation\n",
        "from IPython.display import HTML, Image\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn-white')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pnr_09MP7VsM"
      },
      "outputs": [],
      "source": [
        "#Setup of meshgrid of theta values\n",
        "T1, T2 = np.meshgrid(np.linspace(-5,5,40),np.linspace(-6,3,40))\n",
        "\n",
        "#Computing the cost function for each theta combination\n",
        "zs = np.array(costs)\n",
        "#Reshaping the cost values    \n",
        "Z = zs.reshape(T1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaEBPTzv7VsM"
      },
      "outputs": [],
      "source": [
        "len(thetas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4bHnDLz7VsN"
      },
      "outputs": [],
      "source": [
        "## Extract 1st value from sublist\n",
        "def Extract_1st(lst): \n",
        "    return [item[0] for item in lst] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv3vr0kR7VsN"
      },
      "outputs": [],
      "source": [
        "theta_0 = list(Extract_1st(thetas))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KRq5ihe7VsO"
      },
      "outputs": [],
      "source": [
        "len(theta_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHNTdtD97VsO"
      },
      "outputs": [],
      "source": [
        "## Extract 2nd value from sublist\n",
        "def Extract_2nd(lst): \n",
        "    return [item[1] for item in lst] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqjTNATo7VsP"
      },
      "outputs": [],
      "source": [
        "theta_1 = list(Extract_2nd(thetas))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Em2Z4X997VsP"
      },
      "outputs": [],
      "source": [
        "len(theta_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gZMr-6x7VsQ"
      },
      "outputs": [],
      "source": [
        "## Extract 2nd value from sublist\n",
        "def Extract_3rd(lst): \n",
        "    return [item[2] for item in lst] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyjvkbUg7VsQ"
      },
      "outputs": [],
      "source": [
        "theta_2 = list(Extract_3rd(thetas))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VgEgd_W7VsR"
      },
      "outputs": [],
      "source": [
        "len(theta_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhxadKHa7VsR"
      },
      "outputs": [],
      "source": [
        "fig2 = plt.figure(figsize = (7,7))\n",
        "ax2 = Axes3D(fig2)\n",
        "\n",
        "#Surface plot\n",
        "ax2.plot_surface(T1, T2, Z, rstride = 5, cstride = 5, cmap = 'jet', alpha=0.5)\n",
        "#ax2.plot(theta_0,theta_1,J_history_reg, marker = '*', color = 'r', alpha = .4, label = 'Gradient descent')\n",
        "\n",
        "ax2.set_xlabel('theta 1')\n",
        "ax2.set_ylabel('theta 2')\n",
        "ax2.set_zlabel('error')\n",
        "##ax2.set_title('RSS gradient descent: Root at {}'.format(theta_result_reg.ravel()))\n",
        "ax2.view_init(45, -45)\n",
        "\n",
        "# Create animation\n",
        "line, = ax2.plot([], [], [], 'r-', label = 'Gradient descent', lw = 1.5)\n",
        "point, = ax2.plot([], [], [], '*', color = 'red')\n",
        "display_value = ax2.text(2., 2., 27.5, '', transform=ax2.transAxes)\n",
        "\n",
        "def init_2():\n",
        "    line.set_data([], [])\n",
        "    line.set_3d_properties([])\n",
        "    point.set_data([], [])\n",
        "    point.set_3d_properties([])\n",
        "    display_value.set_text('')\n",
        "\n",
        "    return line, point, display_value\n",
        "\n",
        "def animate_2(i):\n",
        "    # Animate line\n",
        "    line.set_data(theta_0[:i], theta_1[:i])\n",
        "    line.set_3d_properties(costs[:i])\n",
        "    \n",
        "    # Animate points\n",
        "    point.set_data(theta_0[i], theta_1[i])\n",
        "    point.set_3d_properties(costs[i])\n",
        "\n",
        "    # Animate display value\n",
        "    display_value.set_text('Min = ' + str(costs[i]))\n",
        "\n",
        "    return line, point, display_value\n",
        "\n",
        "ax2.legend(loc = 1)\n",
        "\n",
        "anim2 = animation.FuncAnimation(fig2, animate_2, init_func=init_2,\n",
        "                               frames=len(theta_0), interval=120, \n",
        "                               repeat_delay=60, blit=True)\n",
        "\n",
        "#plt.show()\n",
        "HTML(anim2.to_jshtml())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGE-1C4i7VsS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mkidk1e07VsT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}